{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorboard_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPlhLA71HdPa",
        "colab_type": "text"
      },
      "source": [
        "## Illustrative CNN Model\n",
        "Goal: Define which model architecture is best suited for synthetic data training and testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5gTF9vN9RRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#keras is high level application program interface\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "import time\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard #interface with tensorboard using keras callback\n",
        "\n",
        "import pickle\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b97EzsBvpm5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5b6167e1-1475-4173-e4f0-165a21af69c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZeGSA3j1NKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22bc0e75-424b-48a4-a756-d049108fb177"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK0Kn5xHDosr",
        "colab_type": "text"
      },
      "source": [
        "# Access tensorboard GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJUiOyv5Y57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "194ccdb8-42c6-4aed-c3fd-13f0c32943c3"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=59641c3638b655ea433b5584b623e22e17352b972eb9654aa830e188be383ac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.3 GB  | Proc size: 859.1 MB\n",
            "GPU RAM Free: 11307MB | Used: 134MB | Util   1% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnDVRAW3rUhv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d009dc2a-3dab-4bc4-d3d0-326d8f84c13b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouikad4zglkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13ANzsXArEHa",
        "colab_type": "text"
      },
      "source": [
        "#Set up model paramaters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0_S13rEpTrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#log_dir=\"\\\\content\\\\CNN_7_13\\\\logs\\\\{}\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "log_dir=\"/content/drive/My Drive/CNN_7_16/All Python/logs/{}\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "#/content/drive/My Drive/CNN_7_16/All Python/logs\n",
        "\n",
        "X = np.array(pickle.load(open(\"/content/drive/My Drive/CNN_7_16/All Python/X1.pickle\",\"rb\"))) #images\n",
        "y = np.array(pickle.load(open(\"/content/drive/My Drive/CNN_7_16/All Python/y1.pickle\",\"rb\"))) #labels\n",
        "\n",
        "X = X/255.0 #max number of pixels, normalizing data, scale imagery\n",
        "\n",
        "#can use modelcheckpoint to save on best loss, val accuracy, etc., \n",
        "dense_layers= [0] # [0,1,2]\n",
        "layer_sizes = [64]  # [32,64,128]\n",
        "conv_layers=  [3] # [1,2,3]\n",
        "\n",
        "\n",
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME= \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size, dense_layer, int(time.time())) #begin to iterate through models\n",
        "            tensorboard = TensorBoard(log_dir='/content/drive/My Drive/CNN_7_16/All Python/logs/{}'.format(NAME))     #=log_dir,histogram_freq=1)\n",
        "            print(NAME)\n",
        "            \n",
        "            model = Sequential()\n",
        "\n",
        "#layer 1\n",
        "\n",
        "# pass in number of neurons per layer, then window size we want, then in input shape skip how many feature sets we have\n",
        "# for input shape, skip -1 (how many feature sets we had), start at 1. \n",
        "\n",
        "#I can't figure out why when I start at 1 with color it throws off the # of input samples vs target samples\n",
        "#when it seems like it should start at 300 vs 238.. \n",
        "            model.add(Conv2D(layer_size,(3,3), input_shape=X.shape[1:])) \n",
        "            model.add(Activation(\"relu\"))\n",
        "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "            \n",
        "            for l in range(conv_layer-1):\n",
        "            #layer 2\n",
        "                \n",
        "                model.add(Conv2D(layer_size,(3,3)))\n",
        "                model.add(Activation(\"relu\"))\n",
        "                model.add(MaxPooling2D(pool_size=(2,2)))          \n",
        "                \n",
        "            #layer 3   \n",
        "            \n",
        "            #flatten data\n",
        "            model.add(Flatten()) #Convert 3D feature maps into 1D feature vectors\n",
        "            \n",
        "            for l in range(dense_layer):\n",
        "                model.add(Dense(layer_size))\n",
        "                model.add(Activation(\"relu\"))\n",
        "            \n",
        "            #output layer \n",
        "            \n",
        "            model.add(Dense(1)) #Fully connected\n",
        "            model.add(Activation(\"sigmoid\"))\n",
        "            \n",
        "            model.compile(loss=\"binary_crossentropy\",\n",
        "                         optimizer = \"adam\",\n",
        "                         metrics = ['accuracy']) #could use categorical versus bin cross, adam adaptive learning rate\n",
        "            \n",
        "            \n",
        "            #batch size smaller may be better, epochs see where converge, val_split is a percentage chunk to use for validation testing\n",
        "            \n",
        "            t0=time.time()\n",
        "            history = model.fit(X,y, batch_size=1, epochs = 20, validation_split=0.2, callbacks = [tensorboard])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvyD5byDgXLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "880fee44-df83-4a13-8178-017d51b09ffa"
      },
      "source": [
        "print(y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGoshl6zz_86",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cbe03c5-6eff-4649-8ac5-fec8f3a07f13"
      },
      "source": [
        "print(NAME)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3-conv-64-nodes-0-dense-1596776053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRzUSCCuOLEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "41642dc4-11d5-460c-84fe-c8bcc6ab50c8"
      },
      "source": [
        "#lots we can change to optomize the model \n",
        "#how can we use the model\n",
        "\n",
        "#load in a model and test it on a new image\n",
        "\n",
        "model.save('64x3-CNN.model')\n",
        "#model.save('3-conv-64-nodes-0-dense-1596776053')\n",
        "print(model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: 64x3-CNN.model/assets\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f7b877e3438>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pGUYkDFQxAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb9c3a5f-20f7-4dc9-8d87-790cbab8a859"
      },
      "source": [
        "import cv2\n",
        "CATEGORIES = [\"Neg_Training_Data\",\"Pos_Training_Data\"]\n",
        "\n",
        "def prepare(filepath):\n",
        "  IMG_SIZE=250\n",
        "  img_array = cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
        "  new_array=cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
        "  return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
        "\n",
        "model = tf.keras.models.load_model('64x3-CNN.model')\n",
        "\n",
        "prediction = model.predict([prepare('/content/drive/My Drive/CNN_7_16/All Python/Synthetic_Data/practice/ExPlot7.png')]) #predict a list\n",
        "print(CATEGORIES[int(prediction[0][0])])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neg_Training_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W36zpJkKX4JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}